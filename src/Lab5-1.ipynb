{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c257f6c",
   "metadata": {},
   "source": [
    "# Laboratorio 5\n",
    "\n",
    "En este laboratorio, estaremos repasando los conceptos de Atención y Transformadores. Buscaremos acercanos a la implementación del paper [\"Attention is All you Need\"](https://arxiv.org/abs/1706.03762). Por ello, todas las imagenes que veremos aca son del paper, a menos que se indique lo contrario. \n",
    "\n",
    "Al igual que en laboratorios anteriores, para este laboratorio estaremos usando una herramienta para Jupyter Notebooks que facilitará la calificación, no solo asegurándo que ustedes tengan una nota pronto sino también mostrandoles su nota final al terminar el laboratorio.\n",
    "\n",
    "De nuevo me discupo si algo no sale bien, seguiremos mejorando conforme vayamos iterando. Siempre pido su comprensión y colaboración si algo no funciona como debería. \n",
    "\n",
    "Al igual que en el laboratorio pasado, estaremos usando la librería de Dr John Williamson et al de la University of Glasgow, además de ciertas piezas de código de Dr Bjorn Jensen de su curso de Introduction to Data Science and System de la University of Glasgow para la visualización de sus calificaciones. \n",
    "\n",
    "**NOTA:** Ahora tambien hay una tercera dependecia que se necesita instalar. Ver la celda de abajo por favor\n",
    "\n",
    "<script type=\"text/javascript\" src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de26d3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:35.054364Z",
     "start_time": "2023-08-15T00:37:35.041327Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acb39d7a22bd30fe2f43269db8fc178c",
     "grade": false,
     "grade_id": "cell-d337e90c7330c914",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/johnhw/jhwutils/zipball/master\n",
      "  Downloading https://github.com/johnhw/jhwutils/zipball/master\n",
      "     - 0 bytes ? 0:00:00\n",
      "     \\ 118.3 kB 667.9 kB/s 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: jhwutils\n",
      "  Building wheel for jhwutils (setup.py): started\n",
      "  Building wheel for jhwutils (setup.py): finished with status 'done'\n",
      "  Created wheel for jhwutils: filename=jhwutils-1.2-py3-none-any.whl size=41083 sha256=61e8c760b279e031696395536bf387039f8901c89bf5cffc939f6af84bb1a117\n",
      "  Stored in directory: C:\\Users\\sarap\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-9s1fnt0v\\wheels\\22\\cf\\fc\\464198e5e7ba125a8fc9bb20e6297eb4deac9061eda6860554\n",
      "Successfully built jhwutils\n",
      "Installing collected packages: jhwutils\n",
      "  Attempting uninstall: jhwutils\n",
      "    Found existing installation: jhwutils 1.2\n",
      "    Uninstalling jhwutils-1.2:\n",
      "      Successfully uninstalled jhwutils-1.2\n",
      "Successfully installed jhwutils-1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-image) (3.0)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-image) (2.34.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-image) (2024.7.2)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from packaging>=21->scikit-image) (3.0.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/AlbertS789/lautils/zipball/master\n",
      "  Downloading https://github.com/AlbertS789/lautils/zipball/master\n",
      "     - 0 bytes ? 0:00:00\n",
      "     - 4.2 kB ? 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: lautils\n",
      "  Building wheel for lautils (setup.py): started\n",
      "  Building wheel for lautils (setup.py): finished with status 'done'\n",
      "  Created wheel for lautils: filename=lautils-1.0-py3-none-any.whl size=2856 sha256=6e12e07a8b0c9f16c010ff341aaba8fad5f91bb1618c59a62deda0a739ae0376\n",
      "  Stored in directory: C:\\Users\\sarap\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-4pglk0a7\\wheels\\2a\\48\\f3\\ce4089427ce7f6d240b19ac257e642e536e93232f7e6b7e1b5\n",
      "Successfully built lautils\n",
      "Installing collected packages: lautils\n",
      "  Attempting uninstall: lautils\n",
      "    Found existing installation: lautils 1.0\n",
      "    Uninstalling lautils-1.0:\n",
      "      Successfully uninstalled lautils-1.0\n",
      "Successfully installed lautils-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sarap\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Una vez instalada la librería por favor, recuerden volverla a comentar.\n",
    "#!pip install -U --force-reinstall --no-cache https://github.com/johnhw/jhwutils/zipball/master\n",
    "#!pip install scikit-image\n",
    "#!pip install -U --force-reinstall --no-cache https://github.com/AlbertS789/lautils/zipball/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f8b025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-20T02:07:40.915826Z",
     "start_time": "2023-08-20T02:07:28.437774Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d930305954bab29143585b31039fbdc8",
     "grade": false,
     "grade_id": "cell-5829eb3649aa440c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "#from IPython import display\n",
    "#from base64 import b64decode\n",
    "\n",
    "\n",
    "# Other imports\n",
    "from unittest.mock import patch\n",
    "from uuid import getnode as get_mac\n",
    "\n",
    "from jhwutils.checkarr import array_hash, check_hash, check_scalar, check_string, array_hash, _check_scalar\n",
    "import jhwutils.image_audio as ia\n",
    "import jhwutils.tick as tick\n",
    "from lautils.gradeutils import new_representation, hex_to_float, compare_numbers, compare_lists_by_percentage, calculate_coincidences_percentage\n",
    "\n",
    "###\n",
    "tick.reset_marks()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538e872f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:36.250534Z",
     "start_time": "2023-08-15T00:37:36.236019Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f658c10aeff9ccd90992ac2552037da",
     "grade": false,
     "grade_id": "cell-559b86f87afcf85c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Seeds\n",
    "seed_ = 2023\n",
    "np.random.seed(seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f89312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:36.266407Z",
     "start_time": "2023-08-15T00:37:36.252492Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "476b5f908e1f909fe0f9c55eb1a3a0bb",
     "grade": true,
     "grade_id": "cell-3985ef836649b844",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Celda escondida para utlidades necesarias, por favor NO edite esta celda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de75720d",
   "metadata": {},
   "source": [
    "###### Información del estudiante en dos variables\n",
    "\n",
    "* carne_1 : un string con su carne (e.g. \"12281\"), debe ser de al menos 5 caracteres.\n",
    "* firma_mecanografiada_1: un string con su nombre (e.g. \"Albero Suriano\") que se usará para la declaracion que este trabajo es propio (es decir, no hay plagio)\n",
    "* carne_2 : un string con su carne (e.g. \"12281\"), debe ser de al menos 5 caracteres.\n",
    "* firma_mecanografiada_2: un string con su nombre (e.g. \"Albero Suriano\") que se usará para la declaracion que este trabajo es propio (es decir, no hay plagio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997af7e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:36.282242Z",
     "start_time": "2023-08-15T00:37:36.269397Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "449f77f65624316127652ef18b89810f",
     "grade": false,
     "grade_id": "cell-f915e9ab272f87d9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "carne_1 = \"21371\"\n",
    "firma_mecanografiada_1 = \"Sara Echeverria\"\n",
    "carne_2 = \"21289\"\n",
    "firma_mecanografiada_2 = \"Ricardo Mendez\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8684a31f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:55:37.986608Z",
     "start_time": "2023-08-15T00:55:37.976631Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58edc66cd77ae9ecbc7886dd5e9ec45a",
     "grade": true,
     "grade_id": "cell-51da86f6ac657e33",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div class=\"alert alert-box alert-success\">\n",
       "        <h1> <!--{id:\"CORRECTMARK\", marks:\"0\"}--> \n",
       "         ✓ [0 marks] \n",
       "         </h1> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div class=\"alert alert-box alert-success\">\n",
       "        <h1> <!--{id:\"CORRECTMARK\", marks:\"0\"}--> \n",
       "         ✓ [0 marks] \n",
       "         </h1> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deberia poder ver dos checkmarks verdes [0 marks], que indican que su información básica está OK \n",
    "\n",
    "with tick.marks(0): \n",
    "    assert(len(carne_1)>=5 and len(carne_2)>=5)\n",
    "\n",
    "with tick.marks(0):  \n",
    "    assert(len(firma_mecanografiada_1)>0 and len(firma_mecanografiada_2)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032cb53",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "Similar al modelo Seq2Seq, el modelo de Transformer no usará recurrencias, ni tampoco capaz convolucionales. En su lugar, el modelo está hecho meramente con capaz lineales, mecanismos de atención y normalización.\n",
    "\n",
    "Una de las variantes más populares de los Transformadores es BERT (Bidrectional Encoder Representations from Transformers) y versiones pre-entrenadas de BERT que son comunmente usadas para sistituir capaz de embedding (y otras cosas más) en modelos de NLP.\n",
    "\n",
    "Cabe descatar algunas diferencias entre la implentación que haremos y la del paper:\n",
    "\n",
    "* Usaremos un positional encoding aprendido y no uno estático\n",
    "* Usaremos un optimizador estándar Adam con un learning rate estático, en lugar de uno con warm-up y cool-down \n",
    "* No usaremos label smoothing\n",
    "\n",
    "Se consideran estas modificaciones a finalidad de hacer una implementación que se acerque a como BERT suele ser seteado.\n",
    "\n",
    "Consideren que para esta parte estaremos usando el mismo dataset que usamos para la segunda parte del laboratorio pasado. Por ende, sugiero que usen el mismo venv que usaron para esa parte.\n",
    "\n",
    "**Créditos:** Esta parte de este laboratorio está tomado y basado en uno de los repositorios de Ben Trevett\n",
    "\n",
    "### Preparando la Data\n",
    "\n",
    "Como la otra vez, volvemos a empezar importando las librerías necesarias. Así también seteamos la Seed para asegurar que las calificaciones sean consistentes. \n",
    "\n",
    "Despues, al igual que en el lab anterior, haremos el tokenizador. Así mismo definimos mismo Field de la ultima vez con la diferencia menor que ahora estaremos pasando batches de datos, por ende usaremos el parámetr \"batch_first=True\"\n",
    "\n",
    "Despues cargaremos el mismo dataset de la ultima vez \"Multi30K\" para construir nuestro vocabulario. Donde se cargan los sets de `train_data`, `valid_data` y `test_data`, hagan los cambios necesarios para cargar los datos como lo hicieron la última vez. **Siéntase libre de hacer copy-paste de lo que hicieron en el lab4.** \n",
    "\n",
    "Finalmente, definiremos el `device` con el que estaremos trabajando. **Se recomienda usar CUDA**. Por otro lado, recuerden que tienen **disponible el laboratorio del CIT-411** para que lo usen en el período de clase de los días lunes. En las máquinas de este laboratorio pueden usar CUDA y deberían ser más rápidas que los tiempos mostrados en este Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee67dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:37.372076Z",
     "start_time": "2023-08-15T00:37:36.299380Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abdca458f5a8958ecea94fa2cb1bdaa9",
     "grade": false,
     "grade_id": "cell-210657b016e6a12a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a047b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:37.387682Z",
     "start_time": "2023-08-15T00:37:37.373883Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9c9be35cbf891ae86c53e908431ab84",
     "grade": false,
     "grade_id": "cell-2f6d6f39aafb1a4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(seed_)\n",
    "np.random.seed(seed_)\n",
    "torch.manual_seed(seed_)\n",
    "torch.cuda.manual_seed(seed_)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad0a90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:38.599496Z",
     "start_time": "2023-08-15T00:37:37.390483Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0f7eb82159e6405ce10ecefb952da50",
     "grade": false,
     "grade_id": "cell-d20eb45ab17eae05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ab0f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:38.614917Z",
     "start_time": "2023-08-15T00:37:38.601332Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "522db5a69f64e2c3833194bdf8a9a800",
     "grade": false,
     "grade_id": "cell-5b6d056a707bcf13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e399c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:38.631146Z",
     "start_time": "2023-08-15T00:37:38.617662Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dcf493f9c14184289f72c56bd928300",
     "grade": false,
     "grade_id": "cell-785350782f36fd67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Noten el uso de batch_first\n",
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c9699",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:41.871179Z",
     "start_time": "2023-08-15T00:37:38.633309Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1324dd6902ef82ce34f900b1203d8447",
     "grade": false,
     "grade_id": "cell-2a890b2bc340545f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "#                                                    fields = (SRC, TRG))\n",
    "\n",
    "\n",
    "# En esta sección hagan lo mismo que hicieron en el lab4 para cargar\n",
    "# los datos necesarios por favor\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG),\n",
    "                                                    path = 'C:\\\\Users\\\\Al\\\\.cache\\\\torch\\\\text\\\\datasets\\\\\\multi30k2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac6565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.026151Z",
     "start_time": "2023-08-15T00:37:41.873212Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df746de24ea6c3719ef4f75f3f68258f",
     "grade": false,
     "grade_id": "cell-833fb478d4387974",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eec833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.042110Z",
     "start_time": "2023-08-15T00:37:42.031137Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e8efd8e6a14f83de738c082bd831c30",
     "grade": false,
     "grade_id": "cell-a92e23f0886d7aa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Se recomienda el uso de CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545965f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.058196Z",
     "start_time": "2023-08-15T00:37:42.043107Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c9eba4a4c229e7c6402c775368b366b",
     "grade": false,
     "grade_id": "cell-a9814ed615455a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño del batch y creamos iteradores\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a0a39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78fd5fbc6cd60dd5d43ab4a0c91d89f3",
     "grade": false,
     "grade_id": "cell-a0374ffff66fb12a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Construyendo el Modelo\n",
    "\n",
    "A continuación, construiremos el modelo. Al igual que los notebook anteriores, se compone de un *encoder* y un *decoder*, con el encoder *codificando* la oración de entrada/fuente (en alemán) en *vector de contexto* y el decpder luego *decodificando* este vector de contexto para generar nuestra oración de salida/objetivo (en inglés)\n",
    "\n",
    "#### Encoder\n",
    "El codificador de Transformer no intenta comprimir la oración fuente completa, $X = (x_1, ... ,x_n)$, en un solo vector de contexto, $z$. En su lugar, produce una secuencia de vectores de contexto, $Z = (z_1, ... , z_n)$. Entonces, si nuestra secuencia de entrada fuera de 5 tokens, tendríamos $Z = (z_1, z_2, z_3, z_4, z_5)$.\n",
    "\n",
    "¿Por qué llamamos a esto una secuencia de vectores de contexto y no una secuencia de estados ocultos? Un estado oculto en el tiempo $t$ en un RNN solo ha visto tokens $x_t$ y todos los tokens anteriores. Sin embargo, cada vector de contexto aquí ha visto todos los tokens en todas las posiciones dentro de la secuencia de entrada.\n",
    "\n",
    "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/49df8404d938a6edbf729876405558cc2c2b3013//assets/transformer-encoder.png)\n",
    "\n",
    "Primero, los tokens se pasan a través de una capa de embedding estándar. Luego, como el modelo no tiene recurrencia, no tiene idea del orden de los tokens dentro de la secuencia. Resolvemos esto usando una segunda capa de embedding llamada *capa de positional embedding*. Esta es una capa de embedding estándar donde la entrada no es el token en sí, sino la posición del token dentro de la secuencia, comenzando con el primer token, el token `<sos>` (inicio de secuencia), en la posición 0. La posición embeddida tiene un tamaño de \"vocabulario\" de 100, lo que significa que nuestro modelo puede aceptar oraciones de hasta 100 tokens de largo. Esto se puede aumentar si queremos manejar oraciones más largas.\n",
    "\n",
    "La implementación original de Transformer del documento Attention is All You Need no aprende embedding posicionales. En su lugar, utiliza una incrustación estática fija. Las arquitecturas modernas de Transformer, como BERT, usan embedding posicionales en su lugar, por lo que lo haremos asi en este laboratorio. Consulte [esta](http://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding) sección para obtener más información sobre las positional embedding utilizadas en el modelo Transformer original.\n",
    "\n",
    "A continuación, los embedding de tokens y posicionales se suman por elementos para obtener un vector que contiene información sobre el token y también su posición en la secuencia. Sin embargo, antes de que se sumen, las incrustaciones de tokens se multiplican por un factor de escala que es $\\sqrt{d_{model}}$, donde $d_{model}$ es el tamaño del hidden state, `hid_dim`. Esto supuestamente reduce la variación en las incorporaciones y el modelo es difícil de entrenar de manera confiable sin este factor de escala. A continuación, se aplica el dropout a las embeddings combinadas.\n",
    "\n",
    "Las embedding combinadas luego se pasan a través de $N$ *capas de encoder* para obtener $Z$, que luego se van de output y puede ser utilizado por el decoder.\n",
    "\n",
    "La máscara fuente, `src_mask`, tiene simplemente la misma forma que la oración fuente pero tiene un valor de 1 cuando el token en la oración fuente no es un token `<pad>` y 0 cuando es un `<pad>`. simbólico. Esto se usa en las capas del encoder para enmascarar los mecanismos de atención de múltiples cabezas, que se usan para calcular y aplicar atención sobre la oración fuente, por lo que el modelo no presta atención a los tokens `<pad>`, que no contienen información útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8ea3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.074484Z",
     "start_time": "2023-08-15T00:37:42.060171Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bfb25f3ec47b4d758a8136abc9f7c67",
     "grade": false,
     "grade_id": "cell-b020906aa22bcf9d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 n_heads, \n",
    "                 pf_dim,\n",
    "                 dropout, \n",
    "                 device,\n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        \n",
    "        # Aprox 2 lineas para\n",
    "        # self.tok_embedding =\n",
    "        # self.pos_embedding =\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
    "                                                  n_heads, \n",
    "                                                  pf_dim,\n",
    "                                                  dropout, \n",
    "                                                  device) \n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        # Aprox 1 linea para\n",
    "        # self.dropout =\n",
    "        # Hint: Use el valor para dropout dado en la firma del constructor\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        # Noten que el src y el src_mask son lista con informacion dentro de ellas\n",
    "        #src = [batch size, src len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        # Aprox 2 lineas para\n",
    "        # batch_size =\n",
    "        # src_len = \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        \n",
    "        # Noten que pos tendra informacion del batch y el tamanio del src\n",
    "        # pos = [batch size, src len]\n",
    "        \n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        \n",
    "        # src = [batch size, src len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "            \n",
    "        # src = [batch size, src len, hid dim]\n",
    "            \n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a492a7c9",
   "metadata": {},
   "source": [
    "### Capa de Encoder\n",
    "\n",
    "Las capas del encoder son donde está contenida toda la \"carne\" del codificador. Primero pasamos la oración fuente y su máscara a la *capa de atención de múltiples cabezas*, luego realizamos el dropout, aplicamos una conexión residual y la pasamos a través de una [Normalización de capa](https://arxiv.org/abs/1607.06450 ). Luego lo pasamos a través de una capa de *position-wise feedforward* y luego, nuevamente, aplicamos dropout, una conexión residual y luego la normalización de la capa para obtener la salida de esta capa que se alimenta a la siguiente capa. Los parámetros no se comparten entre capas.\n",
    "\n",
    "La capa encoder utiliza la capa de atención de múltiples cabezas para prestar atención a la oración fuente, es decir, está calculando y aplicando atención sobre sí misma en lugar de sobre otra secuencia, por lo que la llamamos *autoatención*.\n",
    "\n",
    "[Este](https://mlexplained.com/2018/01/13/weight-normalization-and-layer-normalization-explained-normalization-in-deep-learning-part-2/) artículo entra en más detalles sobre la capa normalización, pero la esencia es que normaliza los valores de las features, es decir, a través de la hidden dimension, por lo que cada característica tiene una media de 0 y una desviación estándar de 1. Esto permite a las redes neuronales con una mayor cantidad de capas, como el Transformador , el poder entrear más fácil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ffd28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.089677Z",
     "start_time": "2023-08-15T00:37:42.076296Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05ab897605499925278d5b00a2712bdf",
     "grade": false,
     "grade_id": "cell-227fb230ab0a08a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim,  \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        # Aprox 2 lineas para\n",
    "        # self.self_attn_layer_norm =\n",
    "        # self.ff_layer_norm =\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
    "                                                                     pf_dim, \n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, 1, 1, src len] \n",
    "                \n",
    "        # Aprox 1 lineas para self attention\n",
    "        # _src, _ =\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        #dropout, residual connection y layer norm\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        #positionwise feedforward\n",
    "        _src = self.positionwise_feedforward(src)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf673efd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d11466df5043105f315926b6d91c10e0",
     "grade": false,
     "grade_id": "cell-4b6ab78961ddbc36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multi Head Attention Layer\n",
    "Uno de los conceptos clave y novedosos introducidos por el artículo de Transformer es la *capa de atención de múltiples cabezas*.\n",
    "\n",
    "\n",
    "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/49df8404d938a6edbf729876405558cc2c2b3013//assets/transformer-attention.png)\n",
    "\n",
    "La atención se puede considerar como *querys*, *keys* y *values*, donde la query se usa con la key para obtener un vector de atención (generalmente el resultado de una operación *softmax* y tiene todos los values entre 0 y 1 que suma a 1) que luego se usa para obtener una suma ponderada de los values.\n",
    "\n",
    "El transformador utiliza *atención de producto escalar \"escalado\"*, donde la query y la key se combinan tomando el producto escalar entre ellos, luego aplicando la operación softmax y escalando por $d_k$ antes de finalmente multiplicar por el value. $d_k$ que es la *dimensión de la cabeza*, `head_dim`, que explicaremos más adelante.\n",
    "\n",
    "$$ \\text{Atención}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$\n",
    "\n",
    "Esto es similar a la *atención estándar del producto escalar* pero se escala por $d_k$, que según el documento se usa para evitar que los resultados de los productos escalares crezcan demasiado, lo que hace que los gradientes se vuelvan demasiado pequeños.\n",
    "\n",
    "Sin embargo, la atención del producto punto escalado no se aplica simplemente a las querys, keys y values. En lugar de hacer una sola aplicación de atención, las querys, las keys y los valuees tienen su `hid_dim` dividido en $h$ *cabezas* y la atención del producto punto escalado se calcula sobre todas las cabezas en paralelo. Esto significa que en lugar de prestar atención a un concepto por aplicación de atención, prestamos atención a $h$. Luego, volvemos a combinar las cabezas en su forma `hid_dim`, por lo que cada `hid_dim` está potencialmente prestando atención a $h$ conceptos diferentes.\n",
    "\n",
    "$$ \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^O $$\n",
    "\n",
    "$$\\text{cabeza}_i = \\text{Atención}(QW_i^Q, KW_i^K, VW_i^V) $$\n",
    "\n",
    "$W^O$ es la capa lineal aplicada al final de la capa de atención de múltiples cabezas, `fc`. $W^Q, W^K, W^V$ son las capas lineales `fc_q`, `fc_k` y `fc_v`.\n",
    "\n",
    "Recorriendo el módulo, primero calculamos $QW^Q$, $KW^K$ y $VW^V$ con las capas lineales, `fc_q`, `fc_k` y `fc_v`, para obtener `Q`, ` K` y `V`. A continuación, dividimos `hid_dim` de la query, la key y el value en `n_heads` usando `.view` y los permutamos correctamente para que puedan multiplicarse entre sí. Luego calculamos la 'energía' (la atención no normalizada) multiplicando 'Q' y 'K' juntos y escalando por la raíz cuadrada de 'head_dim', que se calcula como 'hid_dim // n_heads'. Luego enmascaramos la energía para que no prestemos atención a ningún elemento de la secuencia que no deberíamos, luego aplicamos el softmax y el dropout. Luego aplicamos la atención a los values caras, `V`, antes de combinar los `n_cabezas`. Finalmente, multiplicamos este $W^O$, representado por `fc_o`.\n",
    "\n",
    "Note que en nuestra implementación, las longitudes de las keys y los values son siempre los mismos, por lo tanto, cuando la matriz multiplica la salida del softmax, `atención`, con `V`, siempre tendremos tamaños de dimensión válidos para la multiplicación de matrices. Esta multiplicación se lleva a cabo usando `torch.matmul` que, cuando ambos tensores son > bidimensionales, realiza una multiplicación matricial por batches sobre las dos últimas dimensiones de cada tensor. Esta será una **[longitud de query, longitud de key] x [longitud de value, atenuación de cabezal]** multiplicación de matriz por batches sobre el tamaño del batch y cada cabezal que proporciona el **[tamaño de batch, n cabezales, longitud de query, atenuación de cabezal ]** resultado.\n",
    "\n",
    "Una cosa que parece extraña al principio es que dropout se aplica directamente a la atención. Esto significa que nuestro vector de atención probablemente no sumará 1 y podemos prestar toda la atención a un token, pero la atención sobre ese token se establece en 0 por dropout. Esto nunca se explica, ni siquiera se menciona, en el documento; sin embargo, lo usa la [implementación oficial](https://github.com/tensorflow/tensor2tensor/) y todas las implementaciones de Transformer desde [BERT] (https:// github.com/google-research/bert/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffed515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.105676Z",
     "start_time": "2023-08-15T00:37:42.092711Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5eff2884d202ca050348224f531628c8",
     "grade": false,
     "grade_id": "cell-7d125b83ae6200ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        # Aprox 4 lineas para\n",
    "        # self.fc_q = \n",
    "        # self.fc_k =\n",
    "        # self.fc_v =\n",
    "        # self.fc_o =\n",
    "        # Hint: Probablemente necesite nn.Linear\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        \n",
    "        #Q = [batch size, query len, hid dim]\n",
    "        #K = [batch size, key len, hid dim]\n",
    "        #V = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        # Aproximadamente 2 lineas para\n",
    "        # K =\n",
    "        # V =\n",
    "        # Hint: Probablemente necesite el metodo .view y .permute\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        #Q = [batch size, n heads, query len, head dim]\n",
    "        #K = [batch size, n heads, key len, head dim]\n",
    "        #V = [batch size, n heads, value len, head dim]\n",
    "                \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        #energy = [batch size, n heads, query len, key len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "                \n",
    "        #attention = [batch size, n heads, query len, key len]\n",
    "                \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        \n",
    "        #x = [batch size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        #x = [batch size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50152e84",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a911caf5d4f8ab052336e164313b5c05",
     "grade": false,
     "grade_id": "cell-9cfcf4befaa34608",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Capa Position-wise Feedforward\n",
    "El otro bloque principal dentro de la capa del encoder es la *capa de realimentación por posición* o *capa position-wise feedforward*. Es relativamente simple en comparación con la capa de atención multi-head. La entrada se transforma de `hid_dim` a `pf_dim`, donde `pf_dim` suele ser mucho más grande que `hid_dim`. El Transformer original usaba un `hid_dim` de 512 y un `pf_dim` de 2048. La función de activación y dropout de ReLU se aplica antes de que se transforme de nuevo en una representación `hid_dim`.\n",
    "\n",
    "¿Por qué se usa esto? Desafortunadamente, nunca se explica en el documento.\n",
    "\n",
    "BERT usa la función de activación [GELU](https://arxiv.org/abs/1606.08415), que se puede usar simplemente cambiando `torch.relu` por `F.gelu`. ¿Por qué usaron GELU? De nuevo, lastimosamente, no se explica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac6987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.120748Z",
     "start_time": "2023-08-15T00:37:42.106674Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd68e30d64c61b52c3cdf3850a9acb54",
     "grade": false,
     "grade_id": "cell-b0852a606228b06c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Aprox 2 lineas para\n",
    "        # self.fc_1 = \n",
    "        # self.fc_2 = \n",
    "        # Hint: hid_dim y pf_dim\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        \n",
    "        #x = [batch size, seq len, pf dim]\n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bab803",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86eb8690aeb542c72f7ae30d6c45ed03",
     "grade": false,
     "grade_id": "cell-14f3d3108eeb6a6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Decoder\n",
    "\n",
    "El objetivo del decoder es tomar la representación codificada de la oración de origen, $Z$, y convertirla en tokens predichos en la oración de destino, $\\hat{Y}$. Luego comparamos $\\hat{Y}$ con los tokens reales en la oración objetivo, $Y$, para calcular nuestra pérdida, que se usará para calcular los gradientes de nuestros parámetros y luego usamos nuestro optimizador para actualizar nuestros pesos en orden para mejorar nuestras predicciones.\n",
    "\n",
    "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/49df8404d938a6edbf729876405558cc2c2b3013//assets/transformer-decoder.png)\n",
    "\n",
    "El decoder es similar al encoder, sin embargo, ahora tiene dos capas de atención multi-head. Una *capa de atención multi-head enmascarada* sobre la secuencia de destino y una capa de atención multi-head que utiliza la representación del decoder como consulta y la representación del encoder como clave y valor.\n",
    "\n",
    "El decoder utiliza positional embeddings y las combina, a través de una suma de elementos, con los tokens de destino embeddidos escalados, seguidos de dropout. Nuevamente, nuestras codificaciones posicionales tienen un \"vocabulario\" de 100, lo que significa que pueden aceptar secuencias de hasta 100 tokens de largo. Esto se puede aumentar si se desea.\n",
    "\n",
    "Las embeddings combinadas luego se pasan a través de las capas del decodificador $N$, junto con la fuente codificada, `enc_src`, y las máscaras de origen y destino. Considere que la cantidad de capas en el encoder no tiene que ser igual a la cantidad de capas en el decoder, aunque ambas se indican con $N$.\n",
    "\n",
    "La representación del decoder después de la capa $N^{th}$ se pasa a través de una capa lineal, `fc_out`. En PyTorch, la operación softmax está contenida dentro de nuestra función de pérdida, por lo que no necesitamos usar explícitamente una capa softmax aquí.\n",
    "\n",
    "Además de usar la máscara de origen, como hicimos en el encoder para evitar que nuestro modelo preste atención a los tokens `<pad>`, también usamos una máscara de destino. Esto se explicará con más detalle en el modelo `Seq2Seq` que encapsula tanto el encoder como el decoder. Como estamos procesando todos los tokens de destino a la vez en paralelo, necesitamos un método para evitar que el decoder \"haga trampa\" simplemente \"mirando\" cuál es el siguiente token en la secuencia de destino y emitiéndolo.\n",
    "\n",
    "Nuestra capa de decoder también genera los valores de atención normalizados para que luego podamos trazarlos y ver a qué está prestando atención nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe1425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.136660Z",
     "start_time": "2023-08-15T00:37:42.121698Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af87a789f88f1a0278c83c566e4eec14",
     "grade": false,
     "grade_id": "cell-aaffd5baa47612d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 n_heads, \n",
    "                 pf_dim, \n",
    "                 dropout, \n",
    "                 device,\n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # Aprox 2 lineas para\n",
    "        # self.tok_embedding =\n",
    "        # self.pos_embedding = \n",
    "        # Hint: output_dim y hid_dim\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            # Aprox 1 linea para \n",
    "            # layer = \n",
    "            # Hint: DecoderLayer\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "                \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "                            \n",
    "        #pos = [batch size, trg len]\n",
    "            \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "                \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            # Aprox 1 linea para\n",
    "            # trg, attetiont = \n",
    "            # Hint: use layer(...)\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "            \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e65fa0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "284a3fd91f8890a6127a9490d2b287ce",
     "grade": false,
     "grade_id": "cell-7f0ab140ac81c0c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Decoder Layer\n",
    "Como se mencionó antes, la capa del decoder es similar a la capa del encoder, excepto que ahora tiene dos capas de atención multi-head, `self_attention` y `encoder_attention`.\n",
    "\n",
    "El primero realiza la autoatención, como en el encoder, utilizando la representación del decoder en cuanto a query, key y value. A esto le sigue el dropout, la conexión residual y la normalización de capas. Esta capa `self_attention` utiliza la máscara de secuencia de destino, `trg_mask`, para evitar que el decoder \"haga trampa\" al prestar atención a los tokens que están \"por delante\" del que está procesando actualmente, ya que procesa todos los tokens en el objetivo. oración en paralelo.\n",
    "\n",
    "El segundo es cómo alimentamos la oración fuente codificada, `enc_src`, en nuestro decoder. En esta capa de atención de multi-head, las queries son las representaciones del decoder y las keys y los values son las representaciones del encoder. Aquí, la máscara de origen, `src_mask` se usa para evitar que la capa de atención multi-head preste atención a los tokens `<pad>` dentro de la oración de origen. A esto le siguen las capas de dropout, conexión residual y normalización de capas.\n",
    "\n",
    "Finalmente, pasamos esto a través de la capa de  position-wise feedforward y otra secuencia más de dropout, conexión residual y normalización de capa.\n",
    "\n",
    "La capa del decoder no presenta ningún concepto nuevo, solo usa el mismo conjunto de capas que el encoder de una manera ligeramente diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41988308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.152305Z",
     "start_time": "2023-08-15T00:37:42.138655Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93076e990b861c9fd91f3595afd1b3db",
     "grade": false,
     "grade_id": "cell-ea18b5a4e82e539c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim, \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Aprox 3 lineas para\n",
    "        # self.self_attn_layer_norm =\n",
    "        # self.enc_attn_layer_norm =\n",
    "        # self.ff_layer_norm = \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
    "                                                                     pf_dim, \n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        #self attention\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "            \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "            \n",
    "        #encoder attention\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "                    \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        #positionwise feedforward\n",
    "        _trg = self.positionwise_feedforward(trg)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142c940",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05ad698ccfaf9a368e0b9859306fdbaf",
     "grade": false,
     "grade_id": "cell-1eb846da06e523e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Modelo Seq2Seq \n",
    "Finalmente, tenemos el módulo `Seq2Seq` que encapsula el encoder y decoder, además de manejar la creación de las máscaras.\n",
    "\n",
    "La máscara de origen se crea comprobando dónde la secuencia de origen no es igual a un token `<pad>`. Es 1 cuando el token no es un token `<pad>` y 0 cuando lo es. Luego se descomprime para que pueda transmitirse correctamente al aplicar la máscara a la `energía`, que tiene la forma **_[tamaño del batch, n cabezas, seq len, seq len]_**.\n",
    "\n",
    "La máscara de destino es un poco más complicada. Primero, creamos una máscara para los tokens `<pad>`, como hicimos con la máscara fuente. A continuación, creamos una máscara \"subsecuente\", `trg_sub_mask`, usando `torch.tril`. Esto crea una matriz diagonal donde los elementos por encima de la diagonal serán cero y los elementos por debajo de la diagonal se establecerán en cualquiera que sea el tensor de entrada. En este caso, el tensor de entrada será un tensor lleno de unos. Esto significa que nuestra `trg_sub_mask` se verá así (para un objetivo con 5 tokens):\n",
    "\n",
    "$$\n",
    "1  0  0  0  0\\\\\n",
    "1  1  0  0  0\\\\\n",
    "1  1  1  0  0\\\\\n",
    "1  1  1  1  0\\\\\n",
    "1  1  1  1  1\\\\\n",
    "$$\n",
    "\n",
    "Esto muestra lo que cada token de destino (fila) puede ver (columna). El primer token de destino tiene una máscara de **_[1, 0, 0, 0, 0]_**, lo que significa que solo puede mirar el primer token de destino. El segundo token de destino tiene una máscara de **_[1, 1, 0, 0, 0]_**, lo que significa que puede ver tanto la primera como la segunda ficha de destino.\n",
    "\n",
    "A continuación, la máscara \"subsecuente\" se combina lógicamente con la máscara de relleno, lo que combina las dos máscaras, lo que garantiza que no se pueda atender ni a los tokens posteriores ni a los tokens de relleno. Por ejemplo, si los dos últimos tokens fueran tokens `<pad>`, la máscara se vería así:\n",
    "\n",
    "$$\n",
    "1  0  0  0  0\\\\\n",
    "1  1  0  0  0\\\\\n",
    "1  1  1  0  0\\\\\n",
    "1  1  1  0  0\\\\\n",
    "1  1  1  0  0\\\\\n",
    "$$\n",
    "\n",
    "Después de crear las máscaras, se utilizan con el encoder y el decoder junto con las oraciones de origen y de destino para obtener nuestra oración de destino predicha, \"salida\", junto con la atención del decoder sobre la secuencia de origen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8787df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:42.168209Z",
     "start_time": "2023-08-15T00:37:42.154164Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dfbdb7f7fe10f8e3be20088952eb5ec",
     "grade": false,
     "grade_id": "cell-1532564591007a69",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder, \n",
    "                 decoder, \n",
    "                 src_pad_idx, \n",
    "                 trg_pad_idx, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Aprox 5 lineas para\n",
    "        # self.encoder = \n",
    "        # self.decoder = \n",
    "        # self.src_pad_idx = \n",
    "        # self.trg_pad_idx = \n",
    "        # self.device = \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        \n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        \n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        \n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "                \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        \n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "                \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd791d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9c6d7ea16243583bd0607c009fb4d36",
     "grade": false,
     "grade_id": "cell-6a30936abcb57cc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Entrenamiento\n",
    "Ahora ya podemos entrenar nuestro modelo, el cual es más pequeño que el modelo usado en el paper original, pero es lo suficientemente robusto.\n",
    "\n",
    "Luego, vamos a definir nuestro modelo completo sequence-to-sequence.\n",
    "\n",
    "Después, creamos una función para contar el número de parámetros, notando que esta vez ya estamos hablando de millones de parametros dentro de un modelo.\n",
    "\n",
    "Más tarde, definimos la forma de iniciar los pesos, usando una técnica conocida como Xavier uniform.\n",
    "\n",
    "Luego, el optimizador utilizado con un learning rate fijo es declarado. Consideren que el learning rate debe ser inferior a la predeterminada utilizada por Adam o, de lo contrario, el aprendizaje es inestable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46de0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.519063Z",
     "start_time": "2023-08-15T00:37:42.170172Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39d8fe528427f96645ebc4c356b99f83",
     "grade": false,
     "grade_id": "cell-4d4df7d3c94c21d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b1f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.549933Z",
     "start_time": "2023-08-15T00:37:43.521009Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e650f8882f5eec23b28f11a76c13b51c",
     "grade": false,
     "grade_id": "cell-fd38ea080f9443e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead92980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.565869Z",
     "start_time": "2023-08-15T00:37:43.550966Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b565b66a977c9daf53037715d6ce63e",
     "grade": false,
     "grade_id": "cell-bc0eeb460e049896",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb7e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.581032Z",
     "start_time": "2023-08-15T00:37:43.566787Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3156cf3c171d68ad7e69c49e0eb63e62",
     "grade": false,
     "grade_id": "cell-4c249e5a1b31389d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e9af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.674671Z",
     "start_time": "2023-08-15T00:37:43.584178Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17fc578fcbdf63c5e6690b4ef4b8b882",
     "grade": false,
     "grade_id": "cell-ee40ffc46a2d900e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model.apply(initialize_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1f85c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.690637Z",
     "start_time": "2023-08-15T00:37:43.676665Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3db79a16ac561596f55e0a287d3850d",
     "grade": false,
     "grade_id": "cell-892680cab08efdd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33640ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.705588Z",
     "start_time": "2023-08-15T00:37:43.692622Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "156ae3448b7c22a092c6f1759ec01f08",
     "grade": false,
     "grade_id": "cell-e8d5e65d680a62d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4fe5a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e7aaef88e023a0568268256efe0191b",
     "grade": false,
     "grade_id": "cell-052d7ba88c7c8b74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Como queremos que nuestro modelo prediga el token `<eos>` pero no que sea una entrada en nuestro modelo, simplemente cortamos el token `<eos>` del final de la secuencia. De este modo:\n",
    "\n",
    "$$ \\text{Atención}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{trg} = [sos, x_1, x_2, x_3, eos]\\\\\n",
    "\\text{trg[:-1]} = [sos, x_1, x_2, x_3]\n",
    "$$\n",
    "\n",
    "$x_i$ denota el elemento de secuencia de destino real. Luego ingresamos esto en el modelo para obtener una secuencia predicha que debería predecir el token `<eos>`:\n",
    "\n",
    "$$\n",
    "\\text{salida} = [y_1, y_2, y_3, eos]\n",
    "$$\n",
    "\n",
    "$y_i$ denota el elemento de secuencia de destino predicho. Luego calculamos nuestra pérdida usando el tensor `trg` original con el token `<sos>` cortado del frente, dejando el token `<eos>`:\n",
    "\n",
    "$$\n",
    "\\text{salida} = [y_1, y_2, y_3, eos]\\\\\n",
    "\\text{trg[1:]} = [x_1, x_2, x_3, eos]\n",
    "$$\n",
    "\n",
    "Luego calculamos nuestras losses y actualizamos nuestros parámetros como es estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f59b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.721662Z",
     "start_time": "2023-08-15T00:37:43.707582Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2621fa6d9a664326a015b72467ac35ef",
     "grade": false,
     "grade_id": "cell-94a0f0c13a74c89b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        # Aprox 1 linea para\n",
    "        # output =\n",
    "        # Hint: Considere usar.contiguos\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180a72a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77c905c633f3b8800ddb3a489a79655a",
     "grade": false,
     "grade_id": "cell-cd5f284d1d0569b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "El ciclo de evaluación es el mismo que el del entrenamiento pero sin la parte de la graiente y la actualizacion de los parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02fee15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.737697Z",
     "start_time": "2023-08-15T00:37:43.723657Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f4f445a1ab1d6baaf0b0d2c872c2114",
     "grade": false,
     "grade_id": "cell-14fb112cbf46928e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f47eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:37:43.753182Z",
     "start_time": "2023-08-15T00:37:43.739693Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0208092e910028b2b5cfba093c9e35f3",
     "grade": false,
     "grade_id": "cell-e913674f3c754c57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36346690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:50.094914Z",
     "start_time": "2023-08-15T00:37:43.754175Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ee3974b8bef1598781d150859ac4857",
     "grade": false,
     "grade_id": "cell-284a2ab136ece792",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Una linea para definir el numero de epocas\n",
    "# N_EPOCHS =\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45ec40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:50.266478Z",
     "start_time": "2023-08-15T00:44:50.097847Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9c2cdf766f5e502e6484bd6aabb995b",
     "grade": false,
     "grade_id": "cell-861a3278292854db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut6-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b4f5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "295bbb0b8cda2689e6b281cb90f264bc",
     "grade": false,
     "grade_id": "cell-e10def7050b3326f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**NB:** La perplejidad (PPL) es una medida utilizada para evaluar la efectividad de un modelo de lenguaje al predecir una secuencia de palabras. Cuantifica qué tan bien el modelo predice la siguiente palabra en una secuencia basada en las palabras anteriores. Una perplejidad más baja indica que el modelo tiene más certeza y precisión en sus predicciones, lo que refleja una mejor comprensión del lenguaje. Por otro lado, una perplejidad más alta sugiere que el modelo tiene menos certeza y le cuesta predecir la siguiente palabra con precisión. La perplejidad se utiliza comúnmente en el procesamiento del lenguaje natural para evaluar la calidad de los modelos de lenguaje, especialmente en tareas como la traducción automática y la generación de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f9b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:50.282549Z",
     "start_time": "2023-08-15T00:44:50.268487Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "007cde74a1e6855f13d0ce41c80e3ff9",
     "grade": true,
     "grade_id": "cell-e75e31cfaa4d346a",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(25):        \n",
    "    assert compare_numbers(new_representation(test_loss), \"3c3d\", '0x1.ae147ae147ae1p+0')\n",
    "    \n",
    "with tick.marks(25):        \n",
    "    assert compare_numbers(new_representation(math.exp(test_loss)), \"3c3d\", '0x1.570a3d70a3d71p+2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5069958",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c61d56f18788a37219ccd462ced8423",
     "grade": false,
     "grade_id": "cell-5770bf63eb133d44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Inferencia\n",
    "Ahora traduciremos desde nuestro modelo con la funcion dada abajo.\n",
    "\n",
    "Los pasos tomados son:\n",
    "- Tokenizar la oración fuente si no ha sido tokenizada (es una cadena)\n",
    "- Agregar los tokens `<sos>` y `<eos>`\n",
    "- Numerizar la oración fuente\n",
    "- Convertirlo en un tensor y agregue una dimensión de lote\n",
    "- Crear la máscara de oración fuente\n",
    "- Introduce la oración fuente y la máscara en el codificador\n",
    "- Cree una lista para contener la oración de salida, inicializada con un token `<sos>`\n",
    "- Si bien no hemos alcanzado una longitud máxima\n",
    "   - Convertir la predicción de la oración de salida actual en un tensor con una dimensión por lotes\n",
    "   - Crear una máscara de oración objetivo\n",
    "   - Coloque la salida actual, la salida del codificador y ambas máscaras en el decodificador\n",
    "   - Obtenga la próxima predicción del token de salida del decodificador junto con la atención\n",
    "   - Agregue predicción a la predicción de oración de salida actual\n",
    "   - Interrumpir si la predicción fue un token `<eos>`\n",
    "- Convertir la oración de salida de índices a tokens\n",
    "- Devolver la oración de salida (con el token `<sos>` eliminado) y la atención de la última capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e14eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:50.297184Z",
     "start_time": "2023-08-15T00:44:50.283549Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8565ee3167fb563a2bf50a15ece1fa40",
     "grade": false,
     "grade_id": "cell-b5188a3de284fe92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de_core_news_sm')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f71658",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff1ccb6a9f107f561cf7b8a42c131117",
     "grade": false,
     "grade_id": "cell-f52ea28c60dc4a20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Ahora definiremos una función que muestra la atención sobre la oración fuente para cada paso de la decodificación. Como este modelo tiene 8 cabezas, nuestro modelo puede ver la atención de cada una de las cabezas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a104d7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:50.328867Z",
     "start_time": "2023-08-15T00:44:50.301819Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "633fd0f931f355f498d4f2c68e359571",
     "grade": false,
     "grade_id": "cell-6b7fc6ca641ebfa8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
    "    \n",
    "    assert n_rows * n_cols == n_heads\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,25))\n",
    "    \n",
    "    for i in range(n_heads):\n",
    "        \n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        \n",
    "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
    "\n",
    "        cax = ax.matshow(_attention, cmap='bone')\n",
    "\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                           rotation=45)\n",
    "        ax.set_yticklabels(['']+translation)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02810ab8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44b544b7d6aa4c04022bc24b1a2a304b",
     "grade": false,
     "grade_id": "cell-d50a43d05e932901",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Ahora es momento de probar nuestro modelo! &#x1F601;\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b711b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:50.344977Z",
     "start_time": "2023-08-15T00:44:50.331873Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2815332b5bfdf751d6f19a3e086d4fc7",
     "grade": false,
     "grade_id": "cell-463d9fe9ecb982ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "example_idx = 8\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a702b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:50.408869Z",
     "start_time": "2023-08-15T00:44:50.348909Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cba2824cabf5beaa5ba9e15cf101945",
     "grade": false,
     "grade_id": "cell-1e0cd497db8e5f26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ccdc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:50.424053Z",
     "start_time": "2023-08-15T00:44:50.409827Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "102bc43e309817fbce7df20cb31823ad",
     "grade": true,
     "grade_id": "cell-0096674ed0d450cb",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(50):        \n",
    "    assert compare_lists_by_percentage(trg, translation, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c6c01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2cca27981f8001a5509616d361f15be8",
     "grade": false,
     "grade_id": "cell-4a2fa73da2255949",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Podemos ver la atención de cada cabeza a continuación. Cada uno es ciertamente diferente, pero es difícil (quizás imposible) razonar sobre a qué ha aprendido realmente la cabeza a prestar atención. Algunas cabezas prestan toda su atención a \"eine\" cuando traducen \"a\", otras no lo hacen en absoluto y otras un poco. Todos parecen seguir el patrón similar de \"escalera descendente\" y la atención al emitir los dos últimos tokens se distribuye por igual entre los dos últimos tokens en la oración de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c2ee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:52.343229Z",
     "start_time": "2023-08-15T00:44:50.432036Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfebe931c932e3ccd6c13703688e49a5",
     "grade": false,
     "grade_id": "cell-7e9c2e8fe816190e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab33d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:52.358493Z",
     "start_time": "2023-08-15T00:44:52.345290Z"
    }
   },
   "outputs": [],
   "source": [
    "example_idx = 7\n",
    "\n",
    "src = vars(valid_data.examples[example_idx])['src']\n",
    "trg = vars(valid_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b4e28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:52.466396Z",
     "start_time": "2023-08-15T00:44:52.359502Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98d428ddb423d9b272c053e423cdb138",
     "grade": false,
     "grade_id": "cell-166898cddb8d99b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0df9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:52.482189Z",
     "start_time": "2023-08-15T00:44:52.467354Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ea4979922f6b8effb38b064e6f083b3",
     "grade": true,
     "grade_id": "cell-286cfb2414e68353",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(50):        \n",
    "    assert compare_lists_by_percentage(trg, translation, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e283bd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3be7611eaefc36f08d21e824d45740c8",
     "grade": false,
     "grade_id": "cell-206ffb0b55751e72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Una vez más, algunas cabezas prestan toda su atención a \"ein\", mientras que otras no le prestan atención. Una vez más, la mayoría de los heads parecen extender su atención sobre los tokens de punto y <eos> en la oración de origen cuando emiten el punto y la oración <eos> en la oración de destino predicha, aunque algunos parecen prestar atención a los tokens cerca del comienzo de la oración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e14d82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:54.624539Z",
     "start_time": "2023-08-15T00:44:52.484329Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80eb096b5eea5a0e65e4e856f8a05ab6",
     "grade": false,
     "grade_id": "cell-0fd7fff7238131b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb907d8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:54.639714Z",
     "start_time": "2023-08-15T00:44:54.626442Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb7e710ca5e77afa27d1785edcfe394e",
     "grade": false,
     "grade_id": "cell-967df8f204a0fac5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "example_idx = 10\n",
    "\n",
    "src = vars(test_data.examples[example_idx])['src']\n",
    "trg = vars(test_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b629f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:54.748290Z",
     "start_time": "2023-08-15T00:44:54.640704Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36992ec8a02f0339d4a31d4b491fe0ec",
     "grade": false,
     "grade_id": "cell-2a6447254fdf9660",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde41559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:54.763438Z",
     "start_time": "2023-08-15T00:44:54.750339Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7d70cc14a992f22862a6dbe4d8817e0",
     "grade": true,
     "grade_id": "cell-81a863f7f367d638",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(50):        \n",
    "    assert compare_lists_by_percentage(trg, translation, 33.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679025c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:56.816015Z",
     "start_time": "2023-08-15T00:44:54.766636Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea3bef5af18ac40a93d9eb1615c29639",
     "grade": false,
     "grade_id": "cell-c07cb66d79e0d46d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f161109",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T08:38:25.007848Z",
     "start_time": "2023-08-14T08:38:24.960784Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df8e69362e2665a12ca817b9bf84f617",
     "grade": false,
     "grade_id": "cell-264b1d50ac74bf74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Calculamos el score BLEU\n",
    "\n",
    "**NB:** El score BLEU (Bilingual Evaluation Understudy) es una métrica para evaluar la calidad de las traducciones generadas por máquinas en comparación con referencias humanas. Mide la superposición de secuencias de n-gramas entre la traducción generada por la máquina y las traducciones de referencia. BLEU calcula la precisión contando los n-gramas coincidentes y también aplica una penalización por brevedad para fomentar traducciones más largas. Produce un puntaje entre 0 y 1, siendo puntajes más altos indicativos de una mejor calidad de traducción, aunque no captura todas las sutilezas de la calidad de la traducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d8f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:44:56.831840Z",
     "start_time": "2023-08-15T00:44:56.817720Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0046279276405f303b20cc2459a3c7c8",
     "grade": false,
     "grade_id": "cell-03a3ba3ea92b0b4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
    "    \n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for datum in data:\n",
    "        \n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "        \n",
    "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
    "        \n",
    "        #cut off <eos> token\n",
    "        pred_trg = pred_trg[:-1]\n",
    "        \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c518be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:46:04.020343Z",
     "start_time": "2023-08-15T00:44:56.833852Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edaa71e73d67db478b2c90aa66babde3",
     "grade": false,
     "grade_id": "cell-015f787de4c116b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bleu_score_ = calculate_bleu(test_data, SRC, TRG, model, device)\n",
    "\n",
    "print(f'BLEU score = {bleu_score_*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f06d2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:49:58.969506Z",
     "start_time": "2023-08-15T00:49:58.950502Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4488f6d31ff48161e210350022faa25c",
     "grade": true,
     "grade_id": "cell-63d81743200ae3e4",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(50):        \n",
    "    assert compare_numbers(new_representation(bleu_score_), \"3e3d\", '0x1.5c28f5c28f5c3p-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f8952",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b5b11ecac215ea5cdf74a326c9bcea7",
     "grade": false,
     "grade_id": "cell-75cd8f269ffa2298",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PREGUNTAS:** Responda las siguintes preguntas en este espacio (10% de la nota)\n",
    "* ¿Cómo afecta la cantidad de parámetros del modelo? ¿Qué nos dicen eso 9M de parametros del modelo que hemos creado?\n",
    "* ¿Qué hace el algoritmo de inicialización de Xavier Uniform?\n",
    "* ¿Qué hace el comando torch.no_grad()?\n",
    "* Interprete el valor obtenido para el BLEU score ¿es nuestro modelo un buen modelo?\n",
    "* ¿Qué puede observar de las palabras donde el modelo se ha confundido?\n",
    "* Observe el comportamiento de la pérdida y PPL en training y validation mientras se entrega el modelo, ¿qué puede decir de estos valores?\n",
    "* Si bien no es una tarea intuitiva o sencilla la interpretación de las gráficas de attention que hemos realizado, intente darle una interpretación a la última de estas gráficas mostrada. ¿Qué tipo de insights podría sacar de esta gráfica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36879e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T00:58:18.044718Z",
     "start_time": "2023-08-15T00:58:18.032219Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53780b870ba4e5232e278b64b641f336",
     "grade": true,
     "grade_id": "cell-c5784ed59a9b5cb2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print()\n",
    "print(\"La fraccion de abajo muestra su rendimiento basado en las partes visibles de este laboratorio\")\n",
    "tick.summarise_marks() # "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
